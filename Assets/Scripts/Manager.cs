using System;
using System.Collections;
using System.Collections.Generic;
using System.Linq;
using ActionLibrary;
using Assets.Scripts;
using Assets.Scripts.Animation;
using UnityEngine;
using IntegratedAuthoringTool;
using IntegratedAuthoringTool.DTOs;
using RolePlayCharacter;
using UnityEngine.UI;
using Utilities;
using WellFormedNames;
using TMPro;
using WorldModel;
using System.IO;
using GAIPS.Rage;
using Microsoft.MixedReality.Toolkit.UI;
using Microsoft.MixedReality.Toolkit.Utilities;
using Microsoft.MixedReality.Toolkit.Experimental.SpatialAwareness;

public class Manager : MonoBehaviour
{

    // Store the iat file
    private IntegratedAuthoringToolAsset _iat;

    //Store the characters
    private List<RolePlayCharacterAsset> _rpcList;

    // Dialogue Text to appear near the player
    private TextMeshPro _dialogueText;

    //Store the World Model
    private WorldModelAsset _worldModel;

    // Prefab to instantiate once theres dialogue options
    public GameObject _dialogueButtonPrefab;

    // Where we instantiate the buttons
    private Transform _dialogueContentParent;

    private RolePlayCharacterAsset _playerRpc;

    private bool _waitingForPlayer = false;

    private List<GameObject> _mButtonList = new List<GameObject>();

    public UnityBodyImplement _agentBodyController;

    public string scenarioName;

    // Use this for initialization
    void Start()
    {

        // Loading Storage json with the Rules, files must be in the Streaming Assets Folder

        var storagePath = Application.streamingAssetsPath + "/" + scenarioName + "/storage.json";
        Debug.Log("Initializing");
        // Making sure it works on Android and Web-GL
        UnityEngine.Networking.UnityWebRequest www = UnityEngine.Networking.UnityWebRequest.Get(storagePath);
        www.SendWebRequest();

        while (!www.isDone)
        {

        }

        String jsonString = www.downloadHandler.text;
        var storage = AssetStorage.FromJson(jsonString);


        //Loading Scenario information with data regarding characters and dialogue
        var iatPath = Application.streamingAssetsPath + "/" + scenarioName+ "/scenario.json";

        //I have to do the same I just did before
        // Making sure it works on Android and Web-GL
        www = UnityEngine.Networking.UnityWebRequest.Get(iatPath);
        www.SendWebRequest();

        while (!www.isDone)
        {

        }

        jsonString = www.downloadHandler.text;

        // Now that I have gotten the string for sure I can load the IAT
        _iat = IntegratedAuthoringToolAsset.FromJson(jsonString, storage);

        var currentState = IATConsts.INITIAL_DIALOGUE_STATE;

        // Getting a list of all the Characters
        _rpcList = _iat.Characters.ToList();

        _rpcList[0].Perceive(EventHelper.ActionEnd(_rpcList[1].CharacterName.ToString(), "Enters", "-"));
        _rpcList[1].Perceive(EventHelper.ActionEnd(_rpcList[0].CharacterName.ToString(), "Enters", "-"));

        //Saving the World Model
        _worldModel = _iat.WorldModel;

        _playerRpc = _rpcList.Find(x => x.CharacterName.ToString().Contains("Interviewer"));
        _playerRpc.IsPlayer = true;

        _dialogueText = GameObject.Find("DialogueText").GetComponent<TextMeshPro>();
        _dialogueContentParent = GameObject.Find("Content").GetComponent<Transform>();


    }



    // Update is called once per frame
    void FixedUpdate()
    {
        if (_waitingForPlayer)
            return;

        if (_agentBodyController._speechController.IsPlaying)
            return;

        IAction finalDecision = null;
        String initiatorAgent = "";

        // A simple cycle to go through all the agents and get their decision (for now there is only the Player and Charlie)
        foreach (var rpc in _rpcList)
        {

            // From all the decisions the rpc wants to perform we want the first one (as it is ordered by priority)
            var decision = rpc.Decide().FirstOrDefault();

            if (rpc.IsPlayer)
            {
                HandlePlayerOptions(decision);
                continue; ;

            }

            if (decision != null)
            {

                initiatorAgent = rpc.CharacterName.ToString();
                finalDecision = decision;

                Debug.Log("Decision:" + finalDecision);

                //Write the decision on the canvas
          //      GameObject.Find("DecisionText").GetComponent<Text>().text =
           //         " " + initiatorAgent + " decided to " + decision.Name.ToString();
                break;
            }

        }


        if (finalDecision != null)

        {
            ChooseDialogue(finalDecision, (Name)initiatorAgent);
        }


        // We can update the Character's Facial Expression each frame to make sure their avatars show emotion
        UpdateAgentFacialExpression();
    }


    void Reply(System.Guid id, Name initiator, Name target)

    {
        Debug.Log("We are replying" + initiator + " and " + target);
        // Retrieving the chosen dialog object
        var dialog = _iat.GetDialogActionById(id);

        // Playing the audio of the dialogue line
        this.StartCoroutine(Speak(id, initiator, target));


        //Writing the dialog on the canvas
       _dialogueText.text =
            initiator + ":  " + dialog.Utterance;


        // Getting the full action Name
        var actualActionName = "Speak(" + dialog.CurrentState + ", " + dialog.NextState + ", " + dialog.Meaning +
                               ", " + dialog.Meaning + ")";

        //So we can generate its event
        var eventName = EventHelper.ActionEnd(initiator, (Name)actualActionName, target);


        ClearAllDialogButtons();

        //Inform each participating agent of what happened
        _rpcList.Find(x => x.CharacterName == initiator).Perceive(eventName);
        _rpcList.Find(x => x.CharacterName == target).Perceive(eventName);

        //Handle the consequences of their actions
        HandleEffects(eventName);
    }


    void HandleEffects(Name _event)
    {
        var consequences = _worldModel.Simulate(new Name[] { _event });

        // For each effect 
        foreach (var eff in consequences)
        {
            Debug.Log("Effect: " + eff.PropertyName + " " + eff.NewValue + " " + eff.ObserverAgent);

            // For each Role Play Character
            foreach (var rpc in _rpcList)
            {

                //If the "Observer" part of the effect corresponds to the name of the agent or if it is a universal symbol
                if (eff.ObserverAgent != rpc.CharacterName && eff.ObserverAgent != (Name)"*") continue;
                //Apply that consequence to the agent
                rpc.Perceive(EventHelper.PropertyChange(eff.PropertyName, eff.NewValue, rpc.CharacterName));

            }
        }

        _waitingForPlayer = false;
    }



    void ChooseDialogue(IAction action, Name initiator)
    {
        Debug.Log(" The agent " + initiator + " decided to perform " + action.Name);

        //                                          NTerm: 0     1     2     3     4
        // If it is a speaking action it is composed by Speak ( [ms], [ns] , [m], [sty])
        var currentState = action.Name.GetNTerm(1);
        var nextState = action.Name.GetNTerm(2);
        var meaning = action.Name.GetNTerm(3);
        var style = action.Name.GetNTerm(4);


        // Returns a list of all the dialogues given the parameters but in this case we only want the first element
        var dialog = _iat.GetDialogueActions(currentState, nextState, meaning, style).FirstOrDefault();


        if (dialog != null)
            Reply(dialog.Id, initiator, action.Target);
    }


    void HandlePlayerOptions(IAction decision)
    {
        _waitingForPlayer = true;

        if (decision != null)
            if (decision.Key.ToString() == "Speak")
            {
                //                                          NTerm: 0     1     2     3     4
                // If it is a speaking action it is composed by Speak ( [ms], [ns] , [m}, [sty])
                var currentState = decision.Name.GetNTerm(1);
                var nextState = decision.Name.GetNTerm(2);
                var meaning = decision.Name.GetNTerm(3);
                var style = decision.Name.GetNTerm(4);


                // Returns a list of all the dialogues given the parameters
                var dialog = _iat.GetDialogueActions(currentState, (Name)"*", (Name)"*", (Name)"*");
                AddDialogueButtons(dialog, decision.Target);


            }

            else Debug.LogWarning("Unknown action: " + decision.Key);
    }


    // Instantiating the Dialog Button Prefab on the DialogueOptions object in the Canvas
    void AddDialogueButtons(List<DialogueStateActionDTO> dialogs, Name target)
    {

        var i = 0;
        foreach (var d in dialogs)
        {
            var b = Instantiate(_dialogueButtonPrefab);

            var t = b.transform;

            t.SetParent(_dialogueContentParent, false);

            i++;

            b.GetComponent<ButtonConfigHelper>().MainLabelText = i + ": " + d.Utterance;
            b.GetComponent<ButtonConfigHelper>().SeeItSayItLabelText = "Say Button " + i;

            var id = d.Id;

            b.GetComponent<Interactable>().OnClick.AddListener(() => Reply(id, _playerRpc.CharacterName, target));

            _mButtonList.Add(b);
           
        }

        _dialogueContentParent.GetComponent<GridObjectCollection>().UpdateCollection();
    }


    void ClearAllDialogButtons()
    {
        foreach (var b in _mButtonList)
        {
            Destroy(b.gameObject);
        }
        _mButtonList.Clear();
    }


    void UpdateAgentFacialExpression()
    {
        //Get the strongest emotion felt by the RPC that is not the Player
        var strongestEmotion = _rpcList.Find(x => x.IsPlayer == false).GetStrongestActiveEmotion();
        Debug.Log("Strongest Emotion:" + strongestEmotion);
        if (_agentBodyController != null && strongestEmotion != null)
            _agentBodyController.SetExpression(strongestEmotion.EmotionType, strongestEmotion.Intensity / 2);


    }


    // Method to play the audio file of the specific dialogue, aka what makes the agent talk
    private IEnumerator Speak(System.Guid id, Name initiator, Name target)
    {

        // The player has no body, so we use a shortcut and ignore him having a voice at all
        if (_playerRpc.CharacterName == initiator)
            yield break;

        // What is the type of of Voice of the agent
        var voiceType = _rpcList.Find(x => x.CharacterName == initiator).VoiceName;

        // Each utterance has a unique Id so we can retrieve its audio file
        var utteranceID = _iat.GetDialogActionById(id).UtteranceId;

        // This path can be changed, for now it is the path we used in this project
        var textToSpeechPath = "/" + scenarioName + "/TTS/" + voiceType + "/" + utteranceID;

        var absolutePath = Application.streamingAssetsPath;


#if UNITY_EDITOR || UNITY_STANDALONE
        absolutePath = "file://" + absolutePath;
#endif

        // Systems tried to "download" the .wav file along with its xml configuration
        string audioUrl = absolutePath + textToSpeechPath + ".wav";
        string xmlUrl = absolutePath + textToSpeechPath + ".xml";

        var audio = new WWW(audioUrl);
        var xml = new WWW(xmlUrl);

        yield return audio;
        yield return xml;

        // If these files were not found there return
        var xmlError = !string.IsNullOrEmpty(xml.error);
        var audioError = !string.IsNullOrEmpty(audio.error);

        if (xmlError)
            Debug.LogError(xml.error);
        if (audioError)
            Debug.LogError(audio.error);

        if (xmlError || audioError)
        {
            yield return new WaitForSeconds(2);
        }

        else
        {

            var clip = audio.GetAudioClip(false);

            // The Unity Body Implement script allows us to play sound clips
            yield return _agentBodyController.PlaySpeech(clip, xml.text);

            clip.UnloadAudioData();
        }
    }
}
